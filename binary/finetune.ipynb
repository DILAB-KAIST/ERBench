{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "'''\n",
    "openai==0.28.1\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"\"\n",
    "\n",
    "openai.api_key = \"\"\n",
    "openai.api_version = '2023-12-01-preview' # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    "'''\n",
    "from openai import AzureOpenAI\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = \"\", \n",
    "  api_key=\"\",  \n",
    "  api_version=\"2023-12-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    ")\n",
    "training_file_name = './finetune_data/soccer_training_set.jsonl' #or training_set.jsonl\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "'''\n",
    "openai==0.28.1\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\", user_provided_filename=\"soccer_training_set.jsonl\"\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "'''\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "openai==0.28.1\n",
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-35-turbo-0613\",\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)\n",
    "'''\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-35-turbo-0613\" # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "#response = openai.FineTuningJob.retrieve(job_id)\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    #response = openai.FineTuningJob.retrieve(job_id)\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "#response = openai.FineTuningJob.list()\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = openai.FineTuningJob.retrieve(job_id)\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(response)\n",
    "fine_tuned_model = response.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
